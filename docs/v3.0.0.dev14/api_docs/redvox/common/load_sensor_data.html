<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.1" />
<title>redvox.common.load_sensor_data API documentation</title>
<meta name="description" content="This module loads or reads sensor data from various sources" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>redvox.common.load_sensor_data</code></h1>
</header>
<section id="section-intro">
<p>This module loads or reads sensor data from various sources</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;
This module loads or reads sensor data from various sources
&#34;&#34;&#34;
import os
import glob
import numpy as np
import pandas as pd
from obspy import read
from typing import List, Dict, Optional
from redvox.api1000 import io as apim_io
from redvox.api900 import reader as api900_io
from redvox.common import file_statistics as fs
from redvox.common import date_time_utils as dtu
from redvox.common.sensor_data import SensorType, SensorData, Station, StationTiming, StationMetadata, DataPacket
from redvox.api1000.wrapped_redvox_packet.sensors import xyz, single
from redvox.api900.timesync.api900_timesync import sync_packet_time_900
from redvox.api1000.wrapped_redvox_packet import wrapped_packet as apim_wp


def calc_evenly_sampled_timestamps(start: float, samples: int, rate_hz: float) -&gt; np.array:
    &#34;&#34;&#34;
    given a start time, calculates samples amount of evenly spaced timestamps at rate_hz
    :param start: float, start timestamp
    :param samples: int, number of samples
    :param rate_hz: float, sample rate in hz
    :return: np.array with evenly spaced timestamps starting at start
    &#34;&#34;&#34;
    return np.array(start + dtu.seconds_to_microseconds(np.arange(0, samples) / rate_hz))


def read_api900_non_mic_sensor(sensor: api900_io.RedvoxSensor, packet_length_s: float, column_id: str) -&gt; SensorData:
    &#34;&#34;&#34;
    read a sensor that does not have mic data from an api900 data packet
    :param sensor: the non-mic api900 sensor to read
    :param packet_length_s: float, the length of the data packet in seconds
    :param column_id: string, used to name the columns
    :return: generic SensorData object
    &#34;&#34;&#34;
    timestamps = sensor.timestamps_microseconds_utc()
    if type(sensor) in [api900_io.AccelerometerSensor, api900_io.MagnetometerSensor, api900_io.GyroscopeSensor]:
        data_for_df = np.transpose([sensor.payload_values_x(), sensor.payload_values_y(), sensor.payload_values_z()])
        columns = [f&#34;{column_id}_x&#34;, f&#34;{column_id}_y&#34;, f&#34;{column_id}_z&#34;]
    else:
        data_for_df = np.transpose(sensor.payload_values())
        columns = [column_id]
    return SensorData(sensor.sensor_name(), pd.DataFrame(data_for_df, index=timestamps, columns=columns),
                      len(timestamps) / packet_length_s, False)


def read_api900_wrapped_packet(wrapped_packet: api900_io.WrappedRedvoxPacket) -&gt; Dict[SensorType, SensorData]:
    &#34;&#34;&#34;
    reads the data from a wrapped api900 redvox packet into a dictionary of generic data
    :param wrapped_packet: a wrapped api900 redvox packet
    :return: a dictionary containing all the sensor data
    &#34;&#34;&#34;
    packet_length_s: float = wrapped_packet.duration_s()
    data_dict: Dict[SensorType, SensorData] = {}
    # there are 9 api900 sensors
    if wrapped_packet.has_microphone_sensor():
        sample_rate_hz = wrapped_packet.microphone_sensor().sample_rate_hz()
        data_for_df = wrapped_packet.microphone_sensor().payload_values()
        timestamps = calc_evenly_sampled_timestamps(
            wrapped_packet.microphone_sensor().first_sample_timestamp_epoch_microseconds_utc(),
            fs.get_num_points_from_sample_rate(sample_rate_hz), sample_rate_hz)
        data_dict[SensorType.AUDIO] = SensorData(wrapped_packet.microphone_sensor().sensor_name(),
                                                 pd.DataFrame(data_for_df, index=timestamps, columns=[&#34;microphone&#34;]),
                                                 sample_rate_hz, True)
    if wrapped_packet.has_accelerometer_sensor():
        data_dict[SensorType.ACCELEROMETER] = read_api900_non_mic_sensor(wrapped_packet.accelerometer_sensor(),
                                                                         packet_length_s, &#34;accelerometer&#34;)
    if wrapped_packet.has_magnetometer_sensor():
        data_dict[SensorType.MAGNETOMETER] = read_api900_non_mic_sensor(wrapped_packet.magnetometer_sensor(),
                                                                        packet_length_s, &#34;magnetometer&#34;)
    if wrapped_packet.has_gyroscope_sensor():
        data_dict[SensorType.GYROSCOPE] = read_api900_non_mic_sensor(wrapped_packet.gyroscope_sensor(),
                                                                     packet_length_s, &#34;gyroscope&#34;)
    if wrapped_packet.has_barometer_sensor():
        data_dict[SensorType.PRESSURE] = read_api900_non_mic_sensor(wrapped_packet.barometer_sensor(),
                                                                    packet_length_s, &#34;barometer&#34;)
    if wrapped_packet.has_light_sensor():
        data_dict[SensorType.LIGHT] = read_api900_non_mic_sensor(wrapped_packet.light_sensor(),
                                                                 packet_length_s, &#34;light&#34;)
    if wrapped_packet.has_infrared_sensor():
        data_dict[SensorType.INFRARED] = read_api900_non_mic_sensor(wrapped_packet.infrared_sensor(),
                                                                    packet_length_s, &#34;infrared&#34;)
    if wrapped_packet.has_image_sensor():
        data_dict[SensorType.IMAGE] = read_api900_non_mic_sensor(wrapped_packet.image_sensor(),
                                                                 packet_length_s, &#34;image&#34;)
    if wrapped_packet.has_location_sensor():
        timestamps = wrapped_packet.location_sensor().timestamps_microseconds_utc()
        data_for_df = np.transpose([wrapped_packet.location_sensor().payload_values_latitude(),
                                    wrapped_packet.location_sensor().payload_values_longitude(),
                                    wrapped_packet.location_sensor().payload_values_altitude(),
                                    wrapped_packet.location_sensor().payload_values_speed(),
                                    wrapped_packet.location_sensor().payload_values_accuracy()])
        columns = [&#34;latitude&#34;, &#34;longitude&#34;, &#34;altitude&#34;, &#34;speed&#34;, &#34;accuracy&#34;]
        data_dict[SensorType.LOCATION] = SensorData(wrapped_packet.location_sensor().sensor_name(),
                                                    pd.DataFrame(data_for_df, index=timestamps, columns=columns),
                                                    len(timestamps) / packet_length_s, False)
    return data_dict


def load_station_from_api900(directory: str, start_timestamp_utc_s: Optional[int] = None,
                             end_timestamp_utc_s: Optional[int] = None) -&gt; Station:
    &#34;&#34;&#34;
    reads in station data from a single api900 file
    :param directory: string of the file to read from
    :param start_timestamp_utc_s: The start timestamp as seconds since the epoch UTC.
    :param end_timestamp_utc_s: The end timestamp as seconds since the epoch UTC.
    :return: a station Object
    &#34;&#34;&#34;
    api900_packet = api900_io.read_rdvxz_file(directory)
    # set station metadata and timing based on first packet
    timing = StationTiming(api900_packet.mach_time_zero(), api900_packet.microphone_sensor().sample_rate_hz(),
                           api900_packet.app_file_start_timestamp_epoch_microseconds_utc(),
                           start_timestamp_utc_s, end_timestamp_utc_s,
                           api900_packet.best_latency(), api900_packet.best_offset())
    metadata = StationMetadata(api900_packet.redvox_id(), api900_packet.device_make(), api900_packet.device_model(),
                               api900_packet.device_os(), api900_packet.device_os_version(),
                               &#34;Redvox&#34;, api900_packet.app_version(), api900_packet.is_scrambled(), timing)
    data_dict = read_api900_wrapped_packet(api900_packet)
    packet_data = DataPacket(api900_packet.server_timestamp_epoch_microseconds_utc(),
                             api900_packet.app_file_start_timestamp_machine(), data_dict,
                             api900_packet.start_timestamp_us_utc(), int(api900_packet.end_timestamp_us_utc()),
                             api900_packet.time_synchronization_sensor().payload_values(),
                             api900_packet.best_latency(), api900_packet.best_offset())
    packet_list: List[DataPacket] = [packet_data]
    return Station(metadata, packet_list)


def load_file_range_from_api900(directory: str,
                                start_timestamp_utc_s: Optional[int] = None,
                                end_timestamp_utc_s: Optional[int] = None,
                                redvox_ids: Optional[List[str]] = None,
                                structured_layout: bool = False,
                                concat_continuous_segments: bool = True) -&gt; List[Station]:
    &#34;&#34;&#34;
    reads in api900 data from a directory and returns a list of stations
    note that the param descriptions are taken directly from api900.reader.read_rdvxz_file_range
    :param directory: The root directory of the data. If structured_layout is False, then this directory will
                      contain various unorganized .rdvxz files. If structured_layout is True, then this directory
                      must be the root api900 directory of the structured files.
    :param start_timestamp_utc_s: The start timestamp as seconds since the epoch UTC.
    :param end_timestamp_utc_s: The end timestamp as seconds since the epoch UTC.
    :param redvox_ids: An optional list of redvox_ids to filter against (default=[]).
    :param structured_layout: An optional value to define if this is loading structured data (default=False).
    :param concat_continuous_segments: An optional value to define if this function should concatenate rdvxz files
                                       into multiple continuous rdvxz files separated at gaps.
    :return: a list of Station objects that contain the data
    &#34;&#34;&#34;
    all_stations: List[Station] = []
    all_data = api900_io.read_rdvxz_file_range(directory, start_timestamp_utc_s, end_timestamp_utc_s, redvox_ids,
                                               structured_layout, concat_continuous_segments)
    for redvox_id, wrapped_packets in all_data.items():
        # set station metadata and timing based on first packet
        timing = StationTiming(wrapped_packets[0].mach_time_zero(),
                               wrapped_packets[0].microphone_sensor().sample_rate_hz(),
                               wrapped_packets[0].app_file_start_timestamp_epoch_microseconds_utc(),
                               start_timestamp_utc_s, end_timestamp_utc_s,
                               wrapped_packets[0].best_latency(), wrapped_packets[0].best_offset())
        metadata = StationMetadata(redvox_id, wrapped_packets[0].device_make(), wrapped_packets[0].device_model(),
                                   wrapped_packets[0].device_os(), wrapped_packets[0].device_os_version(),
                                   &#34;Redvox&#34;, wrapped_packets[0].app_version(), wrapped_packets[0].is_scrambled(),
                                   timing)
        # add data from packets
        packet_list: List[DataPacket] = []
        for packet in wrapped_packets:
            if packet.has_time_synchronization_sensor():
                time_sync = packet.time_synchronization_sensor().payload_values()
            else:
                time_sync = None
            data_dict = read_api900_wrapped_packet(packet)
            packet_data = DataPacket(packet.server_timestamp_epoch_microseconds_utc(),
                                     packet.app_file_start_timestamp_machine(), data_dict,
                                     packet.start_timestamp_us_utc(), packet.end_timestamp_us_utc(),
                                     time_sync, packet.best_latency(), packet.best_offset())
            packet_list.append(packet_data)

        # create the Station data object
        all_stations.append(Station(metadata, packet_list))

    return all_stations


def read_apim_xyz_sensor(sensor: xyz.Xyz, packet_length_s: float, column_id: str) -&gt; SensorData:
    &#34;&#34;&#34;
    read a sensor that has xyz data channels from an api M data packet
    :param sensor: the xyz api M sensor to read
    :param packet_length_s: float, the length of the data packet in seconds
    :param column_id: string, used to name the columns
    :return: generic SensorData object
    &#34;&#34;&#34;
    timestamps = sensor.get_timestamps().get_timestamps()
    data_for_df = np.transpose([sensor.get_x_samples().get_values(),
                                sensor.get_y_samples().get_values(),
                                sensor.get_z_samples().get_values()])
    columns = [f&#34;{column_id}_x&#34;, f&#34;{column_id}_y&#34;, f&#34;{column_id}_z&#34;]
    return SensorData(sensor.get_sensor_description(), pd.DataFrame(data_for_df, index=timestamps, columns=columns),
                      len(timestamps) / packet_length_s, False)


def read_apim_single_sensor(sensor: single.Single, packet_length_s: float, column_id: str) -&gt; SensorData:
    &#34;&#34;&#34;
    read a sensor that has a single data channel from an api M data packet
    :param sensor: the single channel api M sensor to read
    :param packet_length_s: float, the length of the data packet in seconds
    :param column_id: string, used to name the columns
    :return: generic SensorData object
    &#34;&#34;&#34;
    timestamps = sensor.get_timestamps().get_timestamps()
    data_for_df = np.transpose([sensor.get_samples().get_values()])
    columns = [column_id]
    return SensorData(sensor.get_sensor_description(), pd.DataFrame(data_for_df, index=timestamps, columns=columns),
                      len(timestamps) / packet_length_s, False)


def load_apim_wrapped_packet(wrapped_packet: apim_wp.WrappedRedvoxPacketM) -&gt; Dict[SensorType, SensorData]:
    &#34;&#34;&#34;
    reads the data from a wrapped api M redvox packet into a dictionary of generic data
    :param wrapped_packet: a wrapped api M redvox packet
    :return: a dictionary containing all the sensor data
    &#34;&#34;&#34;
    data_dict: Dict[SensorType, SensorData] = {}
    sensors = wrapped_packet.get_sensors()
    # there are 16 api M sensors
    if sensors.has_audio() and sensors.validate_audio():
        sample_rate_hz = sensors.get_audio().get_sample_rate()
        data_for_df = sensors.get_audio().get_samples().get_values()
        timestamps = calc_evenly_sampled_timestamps(sensors.get_audio().get_first_sample_timestamp(),
                                                    len(data_for_df), sample_rate_hz)
        data_dict[SensorType.AUDIO] = SensorData(sensors.get_audio().get_sensor_description(),
                                                 pd.DataFrame(data_for_df, index=timestamps, columns=[&#34;microphone&#34;]),
                                                 sample_rate_hz, True)
        # if audio exists, use it to get the packet duration, otherwise calculate using the packets&#39; timestamps
        packet_length_s: float = sensors.get_audio().get_duration_s()
    else:
        packet_length_s = \
            dtu.microseconds_to_seconds(wrapped_packet.get_timing_information().get_packet_end_mach_timestamp() -
                                        wrapped_packet.get_timing_information().get_packet_start_mach_timestamp())
    if sensors.has_compress_audio() and sensors.validate_compressed_audio():
        sample_rate_hz = sensors.get_compressed_audio().get_sample_rate()
        data_for_df = sensors.get_compressed_audio().get_samples().get_values()
        timestamps = calc_evenly_sampled_timestamps(sensors.get_compressed_audio().get_first_sample_timestamp(),
                                                    len(data_for_df), sample_rate_hz)
        data_dict[SensorType.COMPRESSED_AUDIO] = SensorData(sensors.get_compressed_audio().get_sensor_description(),
                                                            pd.DataFrame(data_for_df, index=timestamps,
                                                                         columns=[&#34;compressed_audio&#34;]),
                                                            sample_rate_hz, True)
    if sensors.has_accelerometer() and sensors.validate_accelerometer():
        data_dict[SensorType.ACCELEROMETER] = read_apim_xyz_sensor(sensors.get_accelerometer(),
                                                                   packet_length_s, &#34;accelerometer&#34;)
    if sensors.has_magnetometer() and sensors.validate_magnetometer():
        data_dict[SensorType.MAGNETOMETER] = read_apim_xyz_sensor(sensors.get_magnetometer(),
                                                                  packet_length_s, &#34;magnetometer&#34;)
    if sensors.has_linear_acceleration() and sensors.validate_accelerometer():
        data_dict[SensorType.LINEAR_ACCELERATION] = read_apim_xyz_sensor(sensors.get_linear_acceleration(),
                                                                         packet_length_s, &#34;linear_accel&#34;)
    if sensors.has_orientation() and sensors.validate_orientation():
        data_dict[SensorType.ORIENTATION] = read_apim_xyz_sensor(sensors.get_orientation(),
                                                                 packet_length_s, &#34;orientation&#34;)
    if sensors.has_rotation_vector() and sensors.validate_rotation_vector():
        data_dict[SensorType.ROTATION_VECTOR] = read_apim_xyz_sensor(sensors.get_rotation_vector(),
                                                                     packet_length_s, &#34;rotation_vector&#34;)
    if sensors.has_gyroscope() and sensors.validate_gyroscope():
        data_dict[SensorType.GYROSCOPE] = read_apim_xyz_sensor(sensors.get_gyroscope(), packet_length_s, &#34;gyroscope&#34;)
    if sensors.has_gravity() and sensors.validate_gravity():
        data_dict[SensorType.GRAVITY] = read_apim_xyz_sensor(sensors.get_gravity(), packet_length_s, &#34;gravity&#34;)
    if sensors.has_pressure() and sensors.validate_pressure():
        data_dict[SensorType.PRESSURE] = read_apim_single_sensor(sensors.get_pressure(), packet_length_s, &#34;barometer&#34;)
    if sensors.has_light() and sensors.validate_light():
        data_dict[SensorType.LIGHT] = read_apim_single_sensor(sensors.get_light(), packet_length_s, &#34;light&#34;)
    if sensors.has_proximity() and sensors.validate_proximity():
        data_dict[SensorType.PROXIMITY] = read_apim_single_sensor(sensors.get_proximity(), packet_length_s, &#34;proximity&#34;)
    if sensors.has_ambient_temperature() and sensors.validate_ambient_temperature():
        data_dict[SensorType.TEMPERATURE] = read_apim_single_sensor(sensors.get_ambient_temperature(),
                                                                    packet_length_s, &#34;ambient_temp&#34;)
    if sensors.has_relative_humidity() and sensors.validate_relative_humidity():
        data_dict[SensorType.RELATIVE_HUMIDITY] = read_apim_single_sensor(sensors.get_relative_humidity(),
                                                                          packet_length_s, &#34;rel_humidity&#34;)
    if sensors.has_image() and sensors.validate_image():
        timestamps = sensors.get_image().get_timestamps().get_timestamps()
        data_for_df = sensors.get_image().get_samples()
        data_dict[SensorType.IMAGE] = SensorData(sensors.get_image().get_sensor_description(),
                                                 pd.DataFrame(data_for_df, index=timestamps, columns=[&#34;image&#34;]),
                                                 len(timestamps) / packet_length_s, False)
    if sensors.has_location() and sensors.validate_location():
        timestamps = sensors.get_location().get_timestamps().get_timestamps()
        data_for_df = np.transpose([sensors.get_location().get_latitude_samples().get_values(),
                                    sensors.get_location().get_longitude_samples().get_values(),
                                    sensors.get_location().get_altitude_samples().get_values(),
                                    sensors.get_location().get_speed_samples().get_values(),
                                    sensors.get_location().get_bearing_samples().get_values(),
                                    sensors.get_location().get_horizontal_accuracy_samples().get_values(),
                                    sensors.get_location().get_vertical_accuracy_samples().get_values(),
                                    sensors.get_location().get_speed_samples().get_values(),
                                    sensors.get_location().get_bearing_accuracy_samples().get_values()])
        columns = [&#34;latitude&#34;, &#34;longitude&#34;, &#34;altitude&#34;, &#34;speed&#34;, &#34;bearing&#34;,
                   &#34;horizontal_accuracy&#34;, &#34;vertical_accuracy&#34;, &#34;speed_accuracy&#34;, &#34;bearing_accuracy&#34;]
        data_dict[SensorType.LOCATION] = SensorData(sensors.get_location().get_sensor_description(),
                                                    pd.DataFrame(data_for_df, index=timestamps, columns=columns),
                                                    len(timestamps) / packet_length_s, False)
    elif sensors.has_location() and sensors.get_location().get_last_best_location():
        timestamps = [sensors.get_location().get_last_best_location().get_latitude_longitude_timestamp().get_mach()]
        data_for_df = np.transpose([[sensors.get_location().get_last_best_location().get_latitude()],
                                    [sensors.get_location().get_last_best_location().get_longitude()],
                                    [sensors.get_location().get_last_best_location().get_altitude()],
                                    [sensors.get_location().get_last_best_location().get_speed()],
                                    [sensors.get_location().get_last_best_location().get_bearing()],
                                    [sensors.get_location().get_last_best_location().get_horizontal_accuracy()],
                                    [sensors.get_location().get_last_best_location().get_vertical_accuracy()],
                                    [sensors.get_location().get_last_best_location().get_speed_accuracy()],
                                    [sensors.get_location().get_last_best_location().get_bearing_accuracy()]])
        columns = [&#34;latitude&#34;, &#34;longitude&#34;, &#34;altitude&#34;, &#34;speed&#34;, &#34;bearing&#34;,
                   &#34;horizontal_accuracy&#34;, &#34;vertical_accuracy&#34;, &#34;speed_accuracy&#34;, &#34;bearing_accuracy&#34;]
        data_dict[SensorType.LOCATION] = SensorData(sensors.get_location().get_sensor_description(),
                                                    pd.DataFrame(data_for_df, index=timestamps, columns=columns),
                                                    len(timestamps) / packet_length_s, False)
    return data_dict


def load_station_from_apim(directory: str, start_timestamp_utc_s: Optional[int] = None,
                           end_timestamp_utc_s: Optional[int] = None) -&gt; Station:
    &#34;&#34;&#34;
    reads in station data from a single api M file
    :param directory: string of the file to read from
    :param start_timestamp_utc_s: The start timestamp as seconds since the epoch UTC.
    :param end_timestamp_utc_s: The end timestamp as seconds since the epoch UTC.
    :return: a station Object
    &#34;&#34;&#34;
    read_packet = apim_io.read_rdvxm_file(directory)
    # set station metadata and timing based on first packet
    if read_packet.get_sensors().validate_audio():
        timing = StationTiming(read_packet.get_timing_information().get_app_start_mach_timestamp(),
                               read_packet.get_sensors().get_audio().get_sample_rate(),
                               read_packet.get_sensors().get_audio().get_first_sample_timestamp(),
                               start_timestamp_utc_s, end_timestamp_utc_s,
                               read_packet.get_timing_information().get_best_latency(),
                               read_packet.get_timing_information().get_best_offset())
    else:
        raise ValueError(&#34;Station is missing Audio sensor!&#34;)
    metadata = StationMetadata(read_packet.get_station_information().get_id(),
                               read_packet.get_station_information().get_make(),
                               read_packet.get_station_information().get_model(),
                               read_packet.get_station_information().get_os().name,
                               read_packet.get_station_information().get_os_version(), &#34;Redvox&#34;,
                               read_packet.get_station_information().get_app_version(),
                               read_packet.get_station_information().get_app_settings().get_scramble_audio_data(),
                               timing)
    # add data from packets
    time_sync = np.array(read_packet.get_timing_information().get_synch_exchanges().get_values())
    data_dict = load_apim_wrapped_packet(read_packet)
    packet_data = DataPacket(read_packet.get_timing_information().get_server_acquisition_arrival_timestamp(),
                             read_packet.get_timing_information().get_app_start_mach_timestamp(), data_dict,
                             read_packet.get_timing_information().get_packet_start_mach_timestamp(),
                             read_packet.get_timing_information().get_packet_end_mach_timestamp(),
                             time_sync, read_packet.get_timing_information().get_best_latency(),
                             read_packet.get_timing_information().get_best_offset())
    packet_list: List[DataPacket] = [packet_data]
    return Station(metadata, packet_list)


def load_from_file_range_api_m(directory: str,
                               start_timestamp_utc_s: Optional[int] = None,
                               end_timestamp_utc_s: Optional[int] = None,
                               redvox_ids: Optional[List[str]] = None,
                               structured_layout: bool = False) -&gt; List[Station]:
    &#34;&#34;&#34;
    reads in api M data from a directory and returns a list of stations
    :param directory: The root directory of the data. If structured_layout is False, then this directory will
                      contain various unorganized .rdvxm files. If structured_layout is True, then this directory
                      must be the root api1000 directory of the structured files.
    :param start_timestamp_utc_s: The start timestamp in seconds since the epoch UTC.
    :param end_timestamp_utc_s: The end timestamp in seconds since the epoch UTC.
    :param redvox_ids: An optional list of redvox_ids to filter against, default empty list
    :param structured_layout: An optional value to define if this is loading structured data, default False.
    :return: a list of Station objects that contain the data
    &#34;&#34;&#34;
    all_stations: List[Station] = []
    all_data = apim_io.read_structured(directory, start_timestamp_utc_s, end_timestamp_utc_s, redvox_ids,
                                       structured_layout)
    for read_packets in all_data.all_wrapped_packets:
        # set station metadata and timing based on first packet
        if read_packets.wrapped_packets[0]:
            if read_packets.wrapped_packets[0].get_sensors().get_audio():
                first_pack = read_packets.wrapped_packets[0]
                timing = StationTiming(read_packets.start_mach_timestamp, read_packets.audio_sample_rate,
                                       first_pack.get_sensors().get_audio().get_first_sample_timestamp(),
                                       start_timestamp_utc_s, end_timestamp_utc_s,
                                       first_pack.get_timing_information().get_best_latency(),
                                       first_pack.get_timing_information().get_best_offset())
                station_info = first_pack.get_station_information()
                metadata = StationMetadata(read_packets.redvox_id, station_info.get_make(), station_info.get_model(),
                                           station_info.get_os().name, station_info.get_os_version(), &#34;Redvox&#34;,
                                           station_info.get_app_version(),
                                           station_info.get_app_settings().get_scramble_audio_data(), timing)
            else:
                raise ValueError(&#34;Packet is missing Audio sensor!&#34;)
        else:
            raise ValueError(&#34;First Packet is missing!&#34;)
        # add data from packets
        packet_list: List[DataPacket] = []
        for packet in read_packets.wrapped_packets:
            time_sync = np.array(packet.get_timing_information().get_synch_exchanges().get_values())
            data_dict = load_apim_wrapped_packet(packet)
            packet_data = DataPacket(packet.get_timing_information().get_server_acquisition_arrival_timestamp(),
                                     packet.get_timing_information().get_app_start_mach_timestamp(), data_dict,
                                     packet.get_timing_information().get_packet_start_mach_timestamp(),
                                     packet.get_timing_information().get_packet_end_mach_timestamp(),
                                     time_sync, packet.get_timing_information().get_best_latency(),
                                     packet.get_timing_information().get_best_offset())
            packet_list.append(packet_data)

        # create the Station data object
        all_stations.append(Station(metadata, packet_list))
    return all_stations


def load_from_mseed(file_path: str) -&gt; List[Station]:
    &#34;&#34;&#34;
    load station data from a miniseed file
    :param file_path: the location of the miniseed file
    :return: a list of Station objects that contain the data
    &#34;&#34;&#34;
    stations: List[Station] = []
    strm = read(file_path)
    for data_stream in strm:
        record_info = data_stream.meta
        start_time = int(dtu.seconds_to_microseconds(data_stream.meta[&#34;starttime&#34;].timestamp))
        end_time = int(dtu.seconds_to_microseconds(data_stream.meta[&#34;endtime&#34;].timestamp))
        station_timing = StationTiming(np.nan, record_info[&#34;sampling_rate&#34;], start_time, start_time, end_time)
        metadata = StationMetadata(record_info[&#34;network&#34;] + record_info[&#34;station&#34;] + &#34;_&#34; + record_info[&#34;location&#34;],
                                   &#34;mb3_make&#34;, &#34;mb3_model&#34;, &#34;mb3_os&#34;, &#34;mb3_os_vers&#34;, &#34;mb3_recorder&#34;,
                                   &#34;mb3_recorder_version&#34;, False, station_timing, record_info[&#34;calib&#34;],
                                   record_info[&#34;network&#34;], record_info[&#34;station&#34;], record_info[&#34;location&#34;],
                                   record_info[&#34;channel&#34;], record_info[&#34;mseed&#34;][&#34;encoding&#34;])
        sample_rate_hz = record_info[&#34;sampling_rate&#34;]
        data_for_df = data_stream.data
        timestamps = calc_evenly_sampled_timestamps(start_time, int(record_info[&#34;npts&#34;]), sample_rate_hz)
        sensor_data = SensorData(record_info[&#34;channel&#34;], pd.DataFrame(data_for_df, index=timestamps, columns=[&#34;BDF&#34;]),
                                 record_info[&#34;sampling_rate&#34;], True)
        data_packet = DataPacket(np.nan, start_time, {SensorType.AUDIO: sensor_data}, start_time, end_time)
        stations.append(Station(metadata, [data_packet]))
    return stations


def read_all_in_dir(directory: str,
                    start_timestamp_utc_s: Optional[int] = None,
                    end_timestamp_utc_s: Optional[int] = None,
                    redvox_ids: Optional[List[str]] = None,
                    structured_layout: bool = False,
                    concat_continuous_segments: bool = True) -&gt; List[Station]:
    &#34;&#34;&#34;
    load all data files in the directory
    :param directory: location of all the files; if structured_layout is True, the directory contains a root api1000,
                        api900, or mseed directory, if structured_layout is False, the directory contains unsorted files
    :param start_timestamp_utc_s: The start timestamp as seconds since the epoch UTC.
    :param end_timestamp_utc_s: The end timestamp as seconds since the epoch UTC.
    :param redvox_ids: An optional list of redvox_ids to filter against, default empty list
    :param structured_layout: An optional value to define if this is loading structured data, default False.
    :param concat_continuous_segments: An optional value to define if this function should concatenate rdvxz files
                                       into multiple continuous rdvxz files separated at gaps.  ONLY WORKS FOR API900
    :return: a list of Station objects that contain the data
    &#34;&#34;&#34;
    # create the object to store the data
    stations: List[Station] = []
    # if structured_layout, there should be a specifically named folder in directory
    if structured_layout:
        api900_dir = os.path.join(directory, &#34;api900&#34;)
        if os.path.exists(api900_dir):
            # get api900 data
            stations.extend(load_file_range_from_api900(api900_dir, start_timestamp_utc_s, end_timestamp_utc_s,
                                                        redvox_ids, True, concat_continuous_segments))
        apim_dir = os.path.join(directory, &#34;api1000&#34;)
        if os.path.exists(apim_dir):
            # get api1000 data
            stations.extend(load_from_file_range_api_m(apim_dir, start_timestamp_utc_s, end_timestamp_utc_s,
                                                       redvox_ids, True))
        mseed_dir = os.path.join(directory, &#34;mseed&#34;)
        if os.path.exists(mseed_dir):
            # get mseed data
            all_paths = glob.glob(os.path.join(mseed_dir, &#34;*.mseed&#34;))
            for path in all_paths:
                mseed_data = load_from_mseed(path)
                for mseed_station in mseed_data:
                    if mseed_station.station_metadata.station_id in redvox_ids:
                        stations.append(mseed_station)
        else:
            # structured layout requires api1000 or api900 directory
            raise ValueError(f&#34;{directory} does not contain api900 or api1000 directory.&#34;)
    # load files from unstructured layout
    # get unstructured api 900 data
    stations.extend(load_file_range_from_api900(directory, start_timestamp_utc_s, end_timestamp_utc_s, redvox_ids,
                                                False, concat_continuous_segments))
    # get unstructured api m data
    stations.extend(load_from_file_range_api_m(directory, start_timestamp_utc_s, end_timestamp_utc_s,
                                               redvox_ids, False))
    # get miniseed data
    mseed_paths = glob.glob(os.path.join(directory, &#34;*.mseed&#34;))
    for path in mseed_paths:
        stations.extend(load_from_mseed(path))
    return stations


def read_api900_in_dir_exact(directory: str,
                             start_timestamp_utc_s: Optional[int] = None,
                             end_timestamp_utc_s: Optional[int] = None,
                             start_padding_s: int = 120,
                             end_padding_s: int = 120,
                             gap_time_s: float = 5,
                             redvox_ids: Optional[List[str]] = None,
                             apply_correction: bool = False,
                             structured_layout: bool = False,
                             concat_continuous_segments: bool = True) -&gt; Dict[str, Dict[SensorType, SensorData]]:
    data = api900_io.read_rdvxz_file_range(directory, start_timestamp_utc_s - start_padding_s,
                                           end_timestamp_utc_s + end_padding_s, redvox_ids,
                                           structured_layout, concat_continuous_segments)
    # create the object to store the data
    return_dict: Dict[str, Dict[SensorType, SensorData]] = {}

    # correct data, then convert to SensorData
    for redvox_id, wrapped_packets in data.items():
        # get the id
        short_id = wrapped_packets[0].redvox_id()
        # apply correction if needed
        if apply_correction:
            sync_packet_time_900(wrapped_packets)
        # prepare an empty dict to add data to
        return_dict[short_id] = {}
        for packet in wrapped_packets:
            # read in the packets&#39; data
            for sensor_type, sensor_data in read_api900_wrapped_packet(packet).items():
                if sensor_type in return_dict[short_id].keys():
                    if sensor_type == SensorType.AUDIO:
                        # detect gap between last added timestamp and new data start timestamp
                        last_timestamp = return_dict[short_id][SensorType.AUDIO].last_data_timestamp()
                        first_timestamp = sensor_data.first_data_timestamp()
                        time_diff: float = first_timestamp - last_timestamp
                        if time_diff &gt; dtu.seconds_to_microseconds(gap_time_s):
                            missing_points = int(dtu.microseconds_to_seconds(time_diff) * sensor_data.sample_rate)
                            gap_times = np.vectorize(
                                lambda t: last_timestamp + dtu.seconds_to_microseconds(t / sensor_data.sample_rate))(
                                list(range(1, missing_points)))
                            empty_points = np.empty(missing_points - 1)
                            empty_points[:] = np.nan
                            empty_df = pd.DataFrame(empty_points, index=gap_times, columns=[&#34;microphone&#34;])
                            return_dict[short_id][SensorType.AUDIO].data_df = \
                                pd.concat([return_dict[short_id][SensorType.AUDIO].data_df, empty_df])
                    return_dict[short_id][sensor_type].data_df = \
                        pd.concat([return_dict[short_id][sensor_type].data_df, sensor_data.data_df])
                else:
                    return_dict[short_id][sensor_type] = sensor_data

    # fill in gaps and truncate
    for ids in redvox_ids:
        if ids not in return_dict.keys():
            # error handling
            print(f&#34;WARNING: {ids} doesn&#39;t have any data to read&#34;)
        else:
            # prepare a bunch of information to be used later
            # compute the length in seconds of one sample
            one_sample_s = 1 / return_dict[ids][SensorType.AUDIO].sample_rate
            # get the start and end timestamps + 1 sample to be safe
            start_timestamp = int(dtu.seconds_to_microseconds(start_timestamp_utc_s - one_sample_s))
            end_timestamp = int(dtu.seconds_to_microseconds(end_timestamp_utc_s + one_sample_s))
            # TRUNCATE!  get only the timestamps between the start and end timestamps
            for sensor_types in return_dict[ids].keys():
                # get the timestamps of the data
                df_timestamps = return_dict[ids][sensor_types].data_df.index.to_numpy()
                temp = np.where(
                    (start_timestamp &lt; df_timestamps) &amp; (df_timestamps &lt; end_timestamp))[0]
                new_df = return_dict[ids][sensor_types].data_df.iloc[temp]
                return_dict[ids][sensor_types].data_df = new_df
            if len(return_dict[ids][SensorType.AUDIO].data_df.values) &lt; 1:
                print(f&#34;WARNING: {ids} audio sensor has been truncated and no valid data remains!&#34;)
                return_dict.pop(ids)
            else:
                # FRONT/END GAP FILL!  calculate the audio samples missing based on inputs
                new_df = return_dict[ids][SensorType.AUDIO].data_df
                first_timestamp = return_dict[ids][SensorType.AUDIO].first_data_timestamp()
                start_diff = first_timestamp - dtu.seconds_to_microseconds(start_timestamp_utc_s)
                if start_diff &gt; 0:
                    num_missing_samples = int(dtu.microseconds_to_seconds(start_diff) *
                                              return_dict[ids][SensorType.AUDIO].sample_rate)
                    time_before = np.vectorize(
                        lambda t: first_timestamp - dtu.seconds_to_microseconds(t * one_sample_s))(
                        list(range(1, num_missing_samples)))
                    time_before = time_before[::-1]
                    data = np.empty(num_missing_samples - 1)
                    data[:] = np.nan
                    new_df_values = pd.DataFrame(data, index=time_before, columns=[&#34;microphone&#34;])
                    new_df = new_df_values.append(new_df)
                last_timestamp = return_dict[ids][SensorType.AUDIO].data_df.index[-1]
                last_diff = dtu.seconds_to_microseconds(end_timestamp_utc_s) - last_timestamp
                if last_diff &gt; 0:
                    num_missing_samples = int(dtu.microseconds_to_seconds(last_diff) *
                                              return_dict[ids][SensorType.AUDIO].sample_rate)
                    time_after = np.vectorize(
                        lambda t: last_timestamp + dtu.seconds_to_microseconds(t * one_sample_s))(
                        list(range(1, num_missing_samples)))
                    data = np.empty(num_missing_samples - 1)
                    data[:] = np.nan
                    new_df_values = pd.DataFrame(data, index=time_after, columns=[&#34;microphone&#34;])
                    new_df = new_df.append(new_df_values)
                # ALL DONE!  set the dataframe to the updated dataframe
                return_dict[ids][SensorType.AUDIO].data_df = new_df

    return return_dict</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="redvox.common.load_sensor_data.calc_evenly_sampled_timestamps"><code class="name flex">
<span>def <span class="ident">calc_evenly_sampled_timestamps</span></span>(<span>start: float, samples: int, rate_hz: float) ‑> <built-in function array></span>
</code></dt>
<dd>
<div class="desc"><p>given a start time, calculates samples amount of evenly spaced timestamps at rate_hz
:param start: float, start timestamp
:param samples: int, number of samples
:param rate_hz: float, sample rate in hz
:return: np.array with evenly spaced timestamps starting at start</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def calc_evenly_sampled_timestamps(start: float, samples: int, rate_hz: float) -&gt; np.array:
    &#34;&#34;&#34;
    given a start time, calculates samples amount of evenly spaced timestamps at rate_hz
    :param start: float, start timestamp
    :param samples: int, number of samples
    :param rate_hz: float, sample rate in hz
    :return: np.array with evenly spaced timestamps starting at start
    &#34;&#34;&#34;
    return np.array(start + dtu.seconds_to_microseconds(np.arange(0, samples) / rate_hz))</code></pre>
</details>
</dd>
<dt id="redvox.common.load_sensor_data.load_apim_wrapped_packet"><code class="name flex">
<span>def <span class="ident">load_apim_wrapped_packet</span></span>(<span>wrapped_packet: <a title="redvox.api1000.wrapped_redvox_packet.wrapped_packet.WrappedRedvoxPacketM" href="../api1000/wrapped_redvox_packet/wrapped_packet.html#redvox.api1000.wrapped_redvox_packet.wrapped_packet.WrappedRedvoxPacketM">WrappedRedvoxPacketM</a>) ‑> typing.Dict[<a title="redvox.common.sensor_data.SensorType" href="sensor_data.html#redvox.common.sensor_data.SensorType">SensorType</a>, <a title="redvox.common.sensor_data.SensorData" href="sensor_data.html#redvox.common.sensor_data.SensorData">SensorData</a>]</span>
</code></dt>
<dd>
<div class="desc"><p>reads the data from a wrapped api M redvox packet into a dictionary of generic data
:param wrapped_packet: a wrapped api M redvox packet
:return: a dictionary containing all the sensor data</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_apim_wrapped_packet(wrapped_packet: apim_wp.WrappedRedvoxPacketM) -&gt; Dict[SensorType, SensorData]:
    &#34;&#34;&#34;
    reads the data from a wrapped api M redvox packet into a dictionary of generic data
    :param wrapped_packet: a wrapped api M redvox packet
    :return: a dictionary containing all the sensor data
    &#34;&#34;&#34;
    data_dict: Dict[SensorType, SensorData] = {}
    sensors = wrapped_packet.get_sensors()
    # there are 16 api M sensors
    if sensors.has_audio() and sensors.validate_audio():
        sample_rate_hz = sensors.get_audio().get_sample_rate()
        data_for_df = sensors.get_audio().get_samples().get_values()
        timestamps = calc_evenly_sampled_timestamps(sensors.get_audio().get_first_sample_timestamp(),
                                                    len(data_for_df), sample_rate_hz)
        data_dict[SensorType.AUDIO] = SensorData(sensors.get_audio().get_sensor_description(),
                                                 pd.DataFrame(data_for_df, index=timestamps, columns=[&#34;microphone&#34;]),
                                                 sample_rate_hz, True)
        # if audio exists, use it to get the packet duration, otherwise calculate using the packets&#39; timestamps
        packet_length_s: float = sensors.get_audio().get_duration_s()
    else:
        packet_length_s = \
            dtu.microseconds_to_seconds(wrapped_packet.get_timing_information().get_packet_end_mach_timestamp() -
                                        wrapped_packet.get_timing_information().get_packet_start_mach_timestamp())
    if sensors.has_compress_audio() and sensors.validate_compressed_audio():
        sample_rate_hz = sensors.get_compressed_audio().get_sample_rate()
        data_for_df = sensors.get_compressed_audio().get_samples().get_values()
        timestamps = calc_evenly_sampled_timestamps(sensors.get_compressed_audio().get_first_sample_timestamp(),
                                                    len(data_for_df), sample_rate_hz)
        data_dict[SensorType.COMPRESSED_AUDIO] = SensorData(sensors.get_compressed_audio().get_sensor_description(),
                                                            pd.DataFrame(data_for_df, index=timestamps,
                                                                         columns=[&#34;compressed_audio&#34;]),
                                                            sample_rate_hz, True)
    if sensors.has_accelerometer() and sensors.validate_accelerometer():
        data_dict[SensorType.ACCELEROMETER] = read_apim_xyz_sensor(sensors.get_accelerometer(),
                                                                   packet_length_s, &#34;accelerometer&#34;)
    if sensors.has_magnetometer() and sensors.validate_magnetometer():
        data_dict[SensorType.MAGNETOMETER] = read_apim_xyz_sensor(sensors.get_magnetometer(),
                                                                  packet_length_s, &#34;magnetometer&#34;)
    if sensors.has_linear_acceleration() and sensors.validate_accelerometer():
        data_dict[SensorType.LINEAR_ACCELERATION] = read_apim_xyz_sensor(sensors.get_linear_acceleration(),
                                                                         packet_length_s, &#34;linear_accel&#34;)
    if sensors.has_orientation() and sensors.validate_orientation():
        data_dict[SensorType.ORIENTATION] = read_apim_xyz_sensor(sensors.get_orientation(),
                                                                 packet_length_s, &#34;orientation&#34;)
    if sensors.has_rotation_vector() and sensors.validate_rotation_vector():
        data_dict[SensorType.ROTATION_VECTOR] = read_apim_xyz_sensor(sensors.get_rotation_vector(),
                                                                     packet_length_s, &#34;rotation_vector&#34;)
    if sensors.has_gyroscope() and sensors.validate_gyroscope():
        data_dict[SensorType.GYROSCOPE] = read_apim_xyz_sensor(sensors.get_gyroscope(), packet_length_s, &#34;gyroscope&#34;)
    if sensors.has_gravity() and sensors.validate_gravity():
        data_dict[SensorType.GRAVITY] = read_apim_xyz_sensor(sensors.get_gravity(), packet_length_s, &#34;gravity&#34;)
    if sensors.has_pressure() and sensors.validate_pressure():
        data_dict[SensorType.PRESSURE] = read_apim_single_sensor(sensors.get_pressure(), packet_length_s, &#34;barometer&#34;)
    if sensors.has_light() and sensors.validate_light():
        data_dict[SensorType.LIGHT] = read_apim_single_sensor(sensors.get_light(), packet_length_s, &#34;light&#34;)
    if sensors.has_proximity() and sensors.validate_proximity():
        data_dict[SensorType.PROXIMITY] = read_apim_single_sensor(sensors.get_proximity(), packet_length_s, &#34;proximity&#34;)
    if sensors.has_ambient_temperature() and sensors.validate_ambient_temperature():
        data_dict[SensorType.TEMPERATURE] = read_apim_single_sensor(sensors.get_ambient_temperature(),
                                                                    packet_length_s, &#34;ambient_temp&#34;)
    if sensors.has_relative_humidity() and sensors.validate_relative_humidity():
        data_dict[SensorType.RELATIVE_HUMIDITY] = read_apim_single_sensor(sensors.get_relative_humidity(),
                                                                          packet_length_s, &#34;rel_humidity&#34;)
    if sensors.has_image() and sensors.validate_image():
        timestamps = sensors.get_image().get_timestamps().get_timestamps()
        data_for_df = sensors.get_image().get_samples()
        data_dict[SensorType.IMAGE] = SensorData(sensors.get_image().get_sensor_description(),
                                                 pd.DataFrame(data_for_df, index=timestamps, columns=[&#34;image&#34;]),
                                                 len(timestamps) / packet_length_s, False)
    if sensors.has_location() and sensors.validate_location():
        timestamps = sensors.get_location().get_timestamps().get_timestamps()
        data_for_df = np.transpose([sensors.get_location().get_latitude_samples().get_values(),
                                    sensors.get_location().get_longitude_samples().get_values(),
                                    sensors.get_location().get_altitude_samples().get_values(),
                                    sensors.get_location().get_speed_samples().get_values(),
                                    sensors.get_location().get_bearing_samples().get_values(),
                                    sensors.get_location().get_horizontal_accuracy_samples().get_values(),
                                    sensors.get_location().get_vertical_accuracy_samples().get_values(),
                                    sensors.get_location().get_speed_samples().get_values(),
                                    sensors.get_location().get_bearing_accuracy_samples().get_values()])
        columns = [&#34;latitude&#34;, &#34;longitude&#34;, &#34;altitude&#34;, &#34;speed&#34;, &#34;bearing&#34;,
                   &#34;horizontal_accuracy&#34;, &#34;vertical_accuracy&#34;, &#34;speed_accuracy&#34;, &#34;bearing_accuracy&#34;]
        data_dict[SensorType.LOCATION] = SensorData(sensors.get_location().get_sensor_description(),
                                                    pd.DataFrame(data_for_df, index=timestamps, columns=columns),
                                                    len(timestamps) / packet_length_s, False)
    elif sensors.has_location() and sensors.get_location().get_last_best_location():
        timestamps = [sensors.get_location().get_last_best_location().get_latitude_longitude_timestamp().get_mach()]
        data_for_df = np.transpose([[sensors.get_location().get_last_best_location().get_latitude()],
                                    [sensors.get_location().get_last_best_location().get_longitude()],
                                    [sensors.get_location().get_last_best_location().get_altitude()],
                                    [sensors.get_location().get_last_best_location().get_speed()],
                                    [sensors.get_location().get_last_best_location().get_bearing()],
                                    [sensors.get_location().get_last_best_location().get_horizontal_accuracy()],
                                    [sensors.get_location().get_last_best_location().get_vertical_accuracy()],
                                    [sensors.get_location().get_last_best_location().get_speed_accuracy()],
                                    [sensors.get_location().get_last_best_location().get_bearing_accuracy()]])
        columns = [&#34;latitude&#34;, &#34;longitude&#34;, &#34;altitude&#34;, &#34;speed&#34;, &#34;bearing&#34;,
                   &#34;horizontal_accuracy&#34;, &#34;vertical_accuracy&#34;, &#34;speed_accuracy&#34;, &#34;bearing_accuracy&#34;]
        data_dict[SensorType.LOCATION] = SensorData(sensors.get_location().get_sensor_description(),
                                                    pd.DataFrame(data_for_df, index=timestamps, columns=columns),
                                                    len(timestamps) / packet_length_s, False)
    return data_dict</code></pre>
</details>
</dd>
<dt id="redvox.common.load_sensor_data.load_file_range_from_api900"><code class="name flex">
<span>def <span class="ident">load_file_range_from_api900</span></span>(<span>directory: str, start_timestamp_utc_s: typing.Union[int, NoneType] = None, end_timestamp_utc_s: typing.Union[int, NoneType] = None, redvox_ids: typing.Union[typing.List[str], NoneType] = None, structured_layout: bool = False, concat_continuous_segments: bool = True) ‑> typing.List[<a title="redvox.common.sensor_data.Station" href="sensor_data.html#redvox.common.sensor_data.Station">Station</a>]</span>
</code></dt>
<dd>
<div class="desc"><p>reads in api900 data from a directory and returns a list of stations
note that the param descriptions are taken directly from api900.reader.read_rdvxz_file_range
:param directory: The root directory of the data. If structured_layout is False, then this directory will
contain various unorganized .rdvxz files. If structured_layout is True, then this directory
must be the root api900 directory of the structured files.
:param start_timestamp_utc_s: The start timestamp as seconds since the epoch UTC.
:param end_timestamp_utc_s: The end timestamp as seconds since the epoch UTC.
:param redvox_ids: An optional list of redvox_ids to filter against (default=[]).
:param structured_layout: An optional value to define if this is loading structured data (default=False).
:param concat_continuous_segments: An optional value to define if this function should concatenate rdvxz files
into multiple continuous rdvxz files separated at gaps.
:return: a list of Station objects that contain the data</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_file_range_from_api900(directory: str,
                                start_timestamp_utc_s: Optional[int] = None,
                                end_timestamp_utc_s: Optional[int] = None,
                                redvox_ids: Optional[List[str]] = None,
                                structured_layout: bool = False,
                                concat_continuous_segments: bool = True) -&gt; List[Station]:
    &#34;&#34;&#34;
    reads in api900 data from a directory and returns a list of stations
    note that the param descriptions are taken directly from api900.reader.read_rdvxz_file_range
    :param directory: The root directory of the data. If structured_layout is False, then this directory will
                      contain various unorganized .rdvxz files. If structured_layout is True, then this directory
                      must be the root api900 directory of the structured files.
    :param start_timestamp_utc_s: The start timestamp as seconds since the epoch UTC.
    :param end_timestamp_utc_s: The end timestamp as seconds since the epoch UTC.
    :param redvox_ids: An optional list of redvox_ids to filter against (default=[]).
    :param structured_layout: An optional value to define if this is loading structured data (default=False).
    :param concat_continuous_segments: An optional value to define if this function should concatenate rdvxz files
                                       into multiple continuous rdvxz files separated at gaps.
    :return: a list of Station objects that contain the data
    &#34;&#34;&#34;
    all_stations: List[Station] = []
    all_data = api900_io.read_rdvxz_file_range(directory, start_timestamp_utc_s, end_timestamp_utc_s, redvox_ids,
                                               structured_layout, concat_continuous_segments)
    for redvox_id, wrapped_packets in all_data.items():
        # set station metadata and timing based on first packet
        timing = StationTiming(wrapped_packets[0].mach_time_zero(),
                               wrapped_packets[0].microphone_sensor().sample_rate_hz(),
                               wrapped_packets[0].app_file_start_timestamp_epoch_microseconds_utc(),
                               start_timestamp_utc_s, end_timestamp_utc_s,
                               wrapped_packets[0].best_latency(), wrapped_packets[0].best_offset())
        metadata = StationMetadata(redvox_id, wrapped_packets[0].device_make(), wrapped_packets[0].device_model(),
                                   wrapped_packets[0].device_os(), wrapped_packets[0].device_os_version(),
                                   &#34;Redvox&#34;, wrapped_packets[0].app_version(), wrapped_packets[0].is_scrambled(),
                                   timing)
        # add data from packets
        packet_list: List[DataPacket] = []
        for packet in wrapped_packets:
            if packet.has_time_synchronization_sensor():
                time_sync = packet.time_synchronization_sensor().payload_values()
            else:
                time_sync = None
            data_dict = read_api900_wrapped_packet(packet)
            packet_data = DataPacket(packet.server_timestamp_epoch_microseconds_utc(),
                                     packet.app_file_start_timestamp_machine(), data_dict,
                                     packet.start_timestamp_us_utc(), packet.end_timestamp_us_utc(),
                                     time_sync, packet.best_latency(), packet.best_offset())
            packet_list.append(packet_data)

        # create the Station data object
        all_stations.append(Station(metadata, packet_list))

    return all_stations</code></pre>
</details>
</dd>
<dt id="redvox.common.load_sensor_data.load_from_file_range_api_m"><code class="name flex">
<span>def <span class="ident">load_from_file_range_api_m</span></span>(<span>directory: str, start_timestamp_utc_s: typing.Union[int, NoneType] = None, end_timestamp_utc_s: typing.Union[int, NoneType] = None, redvox_ids: typing.Union[typing.List[str], NoneType] = None, structured_layout: bool = False) ‑> typing.List[<a title="redvox.common.sensor_data.Station" href="sensor_data.html#redvox.common.sensor_data.Station">Station</a>]</span>
</code></dt>
<dd>
<div class="desc"><p>reads in api M data from a directory and returns a list of stations
:param directory: The root directory of the data. If structured_layout is False, then this directory will
contain various unorganized .rdvxm files. If structured_layout is True, then this directory
must be the root api1000 directory of the structured files.
:param start_timestamp_utc_s: The start timestamp in seconds since the epoch UTC.
:param end_timestamp_utc_s: The end timestamp in seconds since the epoch UTC.
:param redvox_ids: An optional list of redvox_ids to filter against, default empty list
:param structured_layout: An optional value to define if this is loading structured data, default False.
:return: a list of Station objects that contain the data</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_from_file_range_api_m(directory: str,
                               start_timestamp_utc_s: Optional[int] = None,
                               end_timestamp_utc_s: Optional[int] = None,
                               redvox_ids: Optional[List[str]] = None,
                               structured_layout: bool = False) -&gt; List[Station]:
    &#34;&#34;&#34;
    reads in api M data from a directory and returns a list of stations
    :param directory: The root directory of the data. If structured_layout is False, then this directory will
                      contain various unorganized .rdvxm files. If structured_layout is True, then this directory
                      must be the root api1000 directory of the structured files.
    :param start_timestamp_utc_s: The start timestamp in seconds since the epoch UTC.
    :param end_timestamp_utc_s: The end timestamp in seconds since the epoch UTC.
    :param redvox_ids: An optional list of redvox_ids to filter against, default empty list
    :param structured_layout: An optional value to define if this is loading structured data, default False.
    :return: a list of Station objects that contain the data
    &#34;&#34;&#34;
    all_stations: List[Station] = []
    all_data = apim_io.read_structured(directory, start_timestamp_utc_s, end_timestamp_utc_s, redvox_ids,
                                       structured_layout)
    for read_packets in all_data.all_wrapped_packets:
        # set station metadata and timing based on first packet
        if read_packets.wrapped_packets[0]:
            if read_packets.wrapped_packets[0].get_sensors().get_audio():
                first_pack = read_packets.wrapped_packets[0]
                timing = StationTiming(read_packets.start_mach_timestamp, read_packets.audio_sample_rate,
                                       first_pack.get_sensors().get_audio().get_first_sample_timestamp(),
                                       start_timestamp_utc_s, end_timestamp_utc_s,
                                       first_pack.get_timing_information().get_best_latency(),
                                       first_pack.get_timing_information().get_best_offset())
                station_info = first_pack.get_station_information()
                metadata = StationMetadata(read_packets.redvox_id, station_info.get_make(), station_info.get_model(),
                                           station_info.get_os().name, station_info.get_os_version(), &#34;Redvox&#34;,
                                           station_info.get_app_version(),
                                           station_info.get_app_settings().get_scramble_audio_data(), timing)
            else:
                raise ValueError(&#34;Packet is missing Audio sensor!&#34;)
        else:
            raise ValueError(&#34;First Packet is missing!&#34;)
        # add data from packets
        packet_list: List[DataPacket] = []
        for packet in read_packets.wrapped_packets:
            time_sync = np.array(packet.get_timing_information().get_synch_exchanges().get_values())
            data_dict = load_apim_wrapped_packet(packet)
            packet_data = DataPacket(packet.get_timing_information().get_server_acquisition_arrival_timestamp(),
                                     packet.get_timing_information().get_app_start_mach_timestamp(), data_dict,
                                     packet.get_timing_information().get_packet_start_mach_timestamp(),
                                     packet.get_timing_information().get_packet_end_mach_timestamp(),
                                     time_sync, packet.get_timing_information().get_best_latency(),
                                     packet.get_timing_information().get_best_offset())
            packet_list.append(packet_data)

        # create the Station data object
        all_stations.append(Station(metadata, packet_list))
    return all_stations</code></pre>
</details>
</dd>
<dt id="redvox.common.load_sensor_data.load_from_mseed"><code class="name flex">
<span>def <span class="ident">load_from_mseed</span></span>(<span>file_path: str) ‑> typing.List[<a title="redvox.common.sensor_data.Station" href="sensor_data.html#redvox.common.sensor_data.Station">Station</a>]</span>
</code></dt>
<dd>
<div class="desc"><p>load station data from a miniseed file
:param file_path: the location of the miniseed file
:return: a list of Station objects that contain the data</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_from_mseed(file_path: str) -&gt; List[Station]:
    &#34;&#34;&#34;
    load station data from a miniseed file
    :param file_path: the location of the miniseed file
    :return: a list of Station objects that contain the data
    &#34;&#34;&#34;
    stations: List[Station] = []
    strm = read(file_path)
    for data_stream in strm:
        record_info = data_stream.meta
        start_time = int(dtu.seconds_to_microseconds(data_stream.meta[&#34;starttime&#34;].timestamp))
        end_time = int(dtu.seconds_to_microseconds(data_stream.meta[&#34;endtime&#34;].timestamp))
        station_timing = StationTiming(np.nan, record_info[&#34;sampling_rate&#34;], start_time, start_time, end_time)
        metadata = StationMetadata(record_info[&#34;network&#34;] + record_info[&#34;station&#34;] + &#34;_&#34; + record_info[&#34;location&#34;],
                                   &#34;mb3_make&#34;, &#34;mb3_model&#34;, &#34;mb3_os&#34;, &#34;mb3_os_vers&#34;, &#34;mb3_recorder&#34;,
                                   &#34;mb3_recorder_version&#34;, False, station_timing, record_info[&#34;calib&#34;],
                                   record_info[&#34;network&#34;], record_info[&#34;station&#34;], record_info[&#34;location&#34;],
                                   record_info[&#34;channel&#34;], record_info[&#34;mseed&#34;][&#34;encoding&#34;])
        sample_rate_hz = record_info[&#34;sampling_rate&#34;]
        data_for_df = data_stream.data
        timestamps = calc_evenly_sampled_timestamps(start_time, int(record_info[&#34;npts&#34;]), sample_rate_hz)
        sensor_data = SensorData(record_info[&#34;channel&#34;], pd.DataFrame(data_for_df, index=timestamps, columns=[&#34;BDF&#34;]),
                                 record_info[&#34;sampling_rate&#34;], True)
        data_packet = DataPacket(np.nan, start_time, {SensorType.AUDIO: sensor_data}, start_time, end_time)
        stations.append(Station(metadata, [data_packet]))
    return stations</code></pre>
</details>
</dd>
<dt id="redvox.common.load_sensor_data.load_station_from_api900"><code class="name flex">
<span>def <span class="ident">load_station_from_api900</span></span>(<span>directory: str, start_timestamp_utc_s: typing.Union[int, NoneType] = None, end_timestamp_utc_s: typing.Union[int, NoneType] = None) ‑> <a title="redvox.common.sensor_data.Station" href="sensor_data.html#redvox.common.sensor_data.Station">Station</a></span>
</code></dt>
<dd>
<div class="desc"><p>reads in station data from a single api900 file
:param directory: string of the file to read from
:param start_timestamp_utc_s: The start timestamp as seconds since the epoch UTC.
:param end_timestamp_utc_s: The end timestamp as seconds since the epoch UTC.
:return: a station Object</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_station_from_api900(directory: str, start_timestamp_utc_s: Optional[int] = None,
                             end_timestamp_utc_s: Optional[int] = None) -&gt; Station:
    &#34;&#34;&#34;
    reads in station data from a single api900 file
    :param directory: string of the file to read from
    :param start_timestamp_utc_s: The start timestamp as seconds since the epoch UTC.
    :param end_timestamp_utc_s: The end timestamp as seconds since the epoch UTC.
    :return: a station Object
    &#34;&#34;&#34;
    api900_packet = api900_io.read_rdvxz_file(directory)
    # set station metadata and timing based on first packet
    timing = StationTiming(api900_packet.mach_time_zero(), api900_packet.microphone_sensor().sample_rate_hz(),
                           api900_packet.app_file_start_timestamp_epoch_microseconds_utc(),
                           start_timestamp_utc_s, end_timestamp_utc_s,
                           api900_packet.best_latency(), api900_packet.best_offset())
    metadata = StationMetadata(api900_packet.redvox_id(), api900_packet.device_make(), api900_packet.device_model(),
                               api900_packet.device_os(), api900_packet.device_os_version(),
                               &#34;Redvox&#34;, api900_packet.app_version(), api900_packet.is_scrambled(), timing)
    data_dict = read_api900_wrapped_packet(api900_packet)
    packet_data = DataPacket(api900_packet.server_timestamp_epoch_microseconds_utc(),
                             api900_packet.app_file_start_timestamp_machine(), data_dict,
                             api900_packet.start_timestamp_us_utc(), int(api900_packet.end_timestamp_us_utc()),
                             api900_packet.time_synchronization_sensor().payload_values(),
                             api900_packet.best_latency(), api900_packet.best_offset())
    packet_list: List[DataPacket] = [packet_data]
    return Station(metadata, packet_list)</code></pre>
</details>
</dd>
<dt id="redvox.common.load_sensor_data.load_station_from_apim"><code class="name flex">
<span>def <span class="ident">load_station_from_apim</span></span>(<span>directory: str, start_timestamp_utc_s: typing.Union[int, NoneType] = None, end_timestamp_utc_s: typing.Union[int, NoneType] = None) ‑> <a title="redvox.common.sensor_data.Station" href="sensor_data.html#redvox.common.sensor_data.Station">Station</a></span>
</code></dt>
<dd>
<div class="desc"><p>reads in station data from a single api M file
:param directory: string of the file to read from
:param start_timestamp_utc_s: The start timestamp as seconds since the epoch UTC.
:param end_timestamp_utc_s: The end timestamp as seconds since the epoch UTC.
:return: a station Object</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_station_from_apim(directory: str, start_timestamp_utc_s: Optional[int] = None,
                           end_timestamp_utc_s: Optional[int] = None) -&gt; Station:
    &#34;&#34;&#34;
    reads in station data from a single api M file
    :param directory: string of the file to read from
    :param start_timestamp_utc_s: The start timestamp as seconds since the epoch UTC.
    :param end_timestamp_utc_s: The end timestamp as seconds since the epoch UTC.
    :return: a station Object
    &#34;&#34;&#34;
    read_packet = apim_io.read_rdvxm_file(directory)
    # set station metadata and timing based on first packet
    if read_packet.get_sensors().validate_audio():
        timing = StationTiming(read_packet.get_timing_information().get_app_start_mach_timestamp(),
                               read_packet.get_sensors().get_audio().get_sample_rate(),
                               read_packet.get_sensors().get_audio().get_first_sample_timestamp(),
                               start_timestamp_utc_s, end_timestamp_utc_s,
                               read_packet.get_timing_information().get_best_latency(),
                               read_packet.get_timing_information().get_best_offset())
    else:
        raise ValueError(&#34;Station is missing Audio sensor!&#34;)
    metadata = StationMetadata(read_packet.get_station_information().get_id(),
                               read_packet.get_station_information().get_make(),
                               read_packet.get_station_information().get_model(),
                               read_packet.get_station_information().get_os().name,
                               read_packet.get_station_information().get_os_version(), &#34;Redvox&#34;,
                               read_packet.get_station_information().get_app_version(),
                               read_packet.get_station_information().get_app_settings().get_scramble_audio_data(),
                               timing)
    # add data from packets
    time_sync = np.array(read_packet.get_timing_information().get_synch_exchanges().get_values())
    data_dict = load_apim_wrapped_packet(read_packet)
    packet_data = DataPacket(read_packet.get_timing_information().get_server_acquisition_arrival_timestamp(),
                             read_packet.get_timing_information().get_app_start_mach_timestamp(), data_dict,
                             read_packet.get_timing_information().get_packet_start_mach_timestamp(),
                             read_packet.get_timing_information().get_packet_end_mach_timestamp(),
                             time_sync, read_packet.get_timing_information().get_best_latency(),
                             read_packet.get_timing_information().get_best_offset())
    packet_list: List[DataPacket] = [packet_data]
    return Station(metadata, packet_list)</code></pre>
</details>
</dd>
<dt id="redvox.common.load_sensor_data.read_all_in_dir"><code class="name flex">
<span>def <span class="ident">read_all_in_dir</span></span>(<span>directory: str, start_timestamp_utc_s: typing.Union[int, NoneType] = None, end_timestamp_utc_s: typing.Union[int, NoneType] = None, redvox_ids: typing.Union[typing.List[str], NoneType] = None, structured_layout: bool = False, concat_continuous_segments: bool = True) ‑> typing.List[<a title="redvox.common.sensor_data.Station" href="sensor_data.html#redvox.common.sensor_data.Station">Station</a>]</span>
</code></dt>
<dd>
<div class="desc"><p>load all data files in the directory
:param directory: location of all the files; if structured_layout is True, the directory contains a root api1000,
api900, or mseed directory, if structured_layout is False, the directory contains unsorted files
:param start_timestamp_utc_s: The start timestamp as seconds since the epoch UTC.
:param end_timestamp_utc_s: The end timestamp as seconds since the epoch UTC.
:param redvox_ids: An optional list of redvox_ids to filter against, default empty list
:param structured_layout: An optional value to define if this is loading structured data, default False.
:param concat_continuous_segments: An optional value to define if this function should concatenate rdvxz files
into multiple continuous rdvxz files separated at gaps.
ONLY WORKS FOR API900
:return: a list of Station objects that contain the data</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def read_all_in_dir(directory: str,
                    start_timestamp_utc_s: Optional[int] = None,
                    end_timestamp_utc_s: Optional[int] = None,
                    redvox_ids: Optional[List[str]] = None,
                    structured_layout: bool = False,
                    concat_continuous_segments: bool = True) -&gt; List[Station]:
    &#34;&#34;&#34;
    load all data files in the directory
    :param directory: location of all the files; if structured_layout is True, the directory contains a root api1000,
                        api900, or mseed directory, if structured_layout is False, the directory contains unsorted files
    :param start_timestamp_utc_s: The start timestamp as seconds since the epoch UTC.
    :param end_timestamp_utc_s: The end timestamp as seconds since the epoch UTC.
    :param redvox_ids: An optional list of redvox_ids to filter against, default empty list
    :param structured_layout: An optional value to define if this is loading structured data, default False.
    :param concat_continuous_segments: An optional value to define if this function should concatenate rdvxz files
                                       into multiple continuous rdvxz files separated at gaps.  ONLY WORKS FOR API900
    :return: a list of Station objects that contain the data
    &#34;&#34;&#34;
    # create the object to store the data
    stations: List[Station] = []
    # if structured_layout, there should be a specifically named folder in directory
    if structured_layout:
        api900_dir = os.path.join(directory, &#34;api900&#34;)
        if os.path.exists(api900_dir):
            # get api900 data
            stations.extend(load_file_range_from_api900(api900_dir, start_timestamp_utc_s, end_timestamp_utc_s,
                                                        redvox_ids, True, concat_continuous_segments))
        apim_dir = os.path.join(directory, &#34;api1000&#34;)
        if os.path.exists(apim_dir):
            # get api1000 data
            stations.extend(load_from_file_range_api_m(apim_dir, start_timestamp_utc_s, end_timestamp_utc_s,
                                                       redvox_ids, True))
        mseed_dir = os.path.join(directory, &#34;mseed&#34;)
        if os.path.exists(mseed_dir):
            # get mseed data
            all_paths = glob.glob(os.path.join(mseed_dir, &#34;*.mseed&#34;))
            for path in all_paths:
                mseed_data = load_from_mseed(path)
                for mseed_station in mseed_data:
                    if mseed_station.station_metadata.station_id in redvox_ids:
                        stations.append(mseed_station)
        else:
            # structured layout requires api1000 or api900 directory
            raise ValueError(f&#34;{directory} does not contain api900 or api1000 directory.&#34;)
    # load files from unstructured layout
    # get unstructured api 900 data
    stations.extend(load_file_range_from_api900(directory, start_timestamp_utc_s, end_timestamp_utc_s, redvox_ids,
                                                False, concat_continuous_segments))
    # get unstructured api m data
    stations.extend(load_from_file_range_api_m(directory, start_timestamp_utc_s, end_timestamp_utc_s,
                                               redvox_ids, False))
    # get miniseed data
    mseed_paths = glob.glob(os.path.join(directory, &#34;*.mseed&#34;))
    for path in mseed_paths:
        stations.extend(load_from_mseed(path))
    return stations</code></pre>
</details>
</dd>
<dt id="redvox.common.load_sensor_data.read_api900_in_dir_exact"><code class="name flex">
<span>def <span class="ident">read_api900_in_dir_exact</span></span>(<span>directory: str, start_timestamp_utc_s: typing.Union[int, NoneType] = None, end_timestamp_utc_s: typing.Union[int, NoneType] = None, start_padding_s: int = 120, end_padding_s: int = 120, gap_time_s: float = 5, redvox_ids: typing.Union[typing.List[str], NoneType] = None, apply_correction: bool = False, structured_layout: bool = False, concat_continuous_segments: bool = True) ‑> typing.Dict[str, typing.Dict[<a title="redvox.common.sensor_data.SensorType" href="sensor_data.html#redvox.common.sensor_data.SensorType">SensorType</a>, <a title="redvox.common.sensor_data.SensorData" href="sensor_data.html#redvox.common.sensor_data.SensorData">SensorData</a>]]</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def read_api900_in_dir_exact(directory: str,
                             start_timestamp_utc_s: Optional[int] = None,
                             end_timestamp_utc_s: Optional[int] = None,
                             start_padding_s: int = 120,
                             end_padding_s: int = 120,
                             gap_time_s: float = 5,
                             redvox_ids: Optional[List[str]] = None,
                             apply_correction: bool = False,
                             structured_layout: bool = False,
                             concat_continuous_segments: bool = True) -&gt; Dict[str, Dict[SensorType, SensorData]]:
    data = api900_io.read_rdvxz_file_range(directory, start_timestamp_utc_s - start_padding_s,
                                           end_timestamp_utc_s + end_padding_s, redvox_ids,
                                           structured_layout, concat_continuous_segments)
    # create the object to store the data
    return_dict: Dict[str, Dict[SensorType, SensorData]] = {}

    # correct data, then convert to SensorData
    for redvox_id, wrapped_packets in data.items():
        # get the id
        short_id = wrapped_packets[0].redvox_id()
        # apply correction if needed
        if apply_correction:
            sync_packet_time_900(wrapped_packets)
        # prepare an empty dict to add data to
        return_dict[short_id] = {}
        for packet in wrapped_packets:
            # read in the packets&#39; data
            for sensor_type, sensor_data in read_api900_wrapped_packet(packet).items():
                if sensor_type in return_dict[short_id].keys():
                    if sensor_type == SensorType.AUDIO:
                        # detect gap between last added timestamp and new data start timestamp
                        last_timestamp = return_dict[short_id][SensorType.AUDIO].last_data_timestamp()
                        first_timestamp = sensor_data.first_data_timestamp()
                        time_diff: float = first_timestamp - last_timestamp
                        if time_diff &gt; dtu.seconds_to_microseconds(gap_time_s):
                            missing_points = int(dtu.microseconds_to_seconds(time_diff) * sensor_data.sample_rate)
                            gap_times = np.vectorize(
                                lambda t: last_timestamp + dtu.seconds_to_microseconds(t / sensor_data.sample_rate))(
                                list(range(1, missing_points)))
                            empty_points = np.empty(missing_points - 1)
                            empty_points[:] = np.nan
                            empty_df = pd.DataFrame(empty_points, index=gap_times, columns=[&#34;microphone&#34;])
                            return_dict[short_id][SensorType.AUDIO].data_df = \
                                pd.concat([return_dict[short_id][SensorType.AUDIO].data_df, empty_df])
                    return_dict[short_id][sensor_type].data_df = \
                        pd.concat([return_dict[short_id][sensor_type].data_df, sensor_data.data_df])
                else:
                    return_dict[short_id][sensor_type] = sensor_data

    # fill in gaps and truncate
    for ids in redvox_ids:
        if ids not in return_dict.keys():
            # error handling
            print(f&#34;WARNING: {ids} doesn&#39;t have any data to read&#34;)
        else:
            # prepare a bunch of information to be used later
            # compute the length in seconds of one sample
            one_sample_s = 1 / return_dict[ids][SensorType.AUDIO].sample_rate
            # get the start and end timestamps + 1 sample to be safe
            start_timestamp = int(dtu.seconds_to_microseconds(start_timestamp_utc_s - one_sample_s))
            end_timestamp = int(dtu.seconds_to_microseconds(end_timestamp_utc_s + one_sample_s))
            # TRUNCATE!  get only the timestamps between the start and end timestamps
            for sensor_types in return_dict[ids].keys():
                # get the timestamps of the data
                df_timestamps = return_dict[ids][sensor_types].data_df.index.to_numpy()
                temp = np.where(
                    (start_timestamp &lt; df_timestamps) &amp; (df_timestamps &lt; end_timestamp))[0]
                new_df = return_dict[ids][sensor_types].data_df.iloc[temp]
                return_dict[ids][sensor_types].data_df = new_df
            if len(return_dict[ids][SensorType.AUDIO].data_df.values) &lt; 1:
                print(f&#34;WARNING: {ids} audio sensor has been truncated and no valid data remains!&#34;)
                return_dict.pop(ids)
            else:
                # FRONT/END GAP FILL!  calculate the audio samples missing based on inputs
                new_df = return_dict[ids][SensorType.AUDIO].data_df
                first_timestamp = return_dict[ids][SensorType.AUDIO].first_data_timestamp()
                start_diff = first_timestamp - dtu.seconds_to_microseconds(start_timestamp_utc_s)
                if start_diff &gt; 0:
                    num_missing_samples = int(dtu.microseconds_to_seconds(start_diff) *
                                              return_dict[ids][SensorType.AUDIO].sample_rate)
                    time_before = np.vectorize(
                        lambda t: first_timestamp - dtu.seconds_to_microseconds(t * one_sample_s))(
                        list(range(1, num_missing_samples)))
                    time_before = time_before[::-1]
                    data = np.empty(num_missing_samples - 1)
                    data[:] = np.nan
                    new_df_values = pd.DataFrame(data, index=time_before, columns=[&#34;microphone&#34;])
                    new_df = new_df_values.append(new_df)
                last_timestamp = return_dict[ids][SensorType.AUDIO].data_df.index[-1]
                last_diff = dtu.seconds_to_microseconds(end_timestamp_utc_s) - last_timestamp
                if last_diff &gt; 0:
                    num_missing_samples = int(dtu.microseconds_to_seconds(last_diff) *
                                              return_dict[ids][SensorType.AUDIO].sample_rate)
                    time_after = np.vectorize(
                        lambda t: last_timestamp + dtu.seconds_to_microseconds(t * one_sample_s))(
                        list(range(1, num_missing_samples)))
                    data = np.empty(num_missing_samples - 1)
                    data[:] = np.nan
                    new_df_values = pd.DataFrame(data, index=time_after, columns=[&#34;microphone&#34;])
                    new_df = new_df.append(new_df_values)
                # ALL DONE!  set the dataframe to the updated dataframe
                return_dict[ids][SensorType.AUDIO].data_df = new_df

    return return_dict</code></pre>
</details>
</dd>
<dt id="redvox.common.load_sensor_data.read_api900_non_mic_sensor"><code class="name flex">
<span>def <span class="ident">read_api900_non_mic_sensor</span></span>(<span>sensor: typing.Union[<a title="redvox.api900.sensors.evenly_sampled_sensor.EvenlySampledSensor" href="../api900/sensors/evenly_sampled_sensor.html#redvox.api900.sensors.evenly_sampled_sensor.EvenlySampledSensor">EvenlySampledSensor</a>, <a title="redvox.api900.sensors.unevenly_sampled_sensor.UnevenlySampledSensor" href="../api900/sensors/unevenly_sampled_sensor.html#redvox.api900.sensors.unevenly_sampled_sensor.UnevenlySampledSensor">UnevenlySampledSensor</a>, <a title="redvox.api900.sensors.microphone_sensor.MicrophoneSensor" href="../api900/sensors/microphone_sensor.html#redvox.api900.sensors.microphone_sensor.MicrophoneSensor">MicrophoneSensor</a>, <a title="redvox.api900.sensors.barometer_sensor.BarometerSensor" href="../api900/sensors/barometer_sensor.html#redvox.api900.sensors.barometer_sensor.BarometerSensor">BarometerSensor</a>, <a title="redvox.api900.sensors.location_sensor.LocationSensor" href="../api900/sensors/location_sensor.html#redvox.api900.sensors.location_sensor.LocationSensor">LocationSensor</a>, <a title="redvox.api900.sensors.time_synchronization_sensor.TimeSynchronizationSensor" href="../api900/sensors/time_synchronization_sensor.html#redvox.api900.sensors.time_synchronization_sensor.TimeSynchronizationSensor">TimeSynchronizationSensor</a>, <a title="redvox.api900.sensors.accelerometer_sensor.AccelerometerSensor" href="../api900/sensors/accelerometer_sensor.html#redvox.api900.sensors.accelerometer_sensor.AccelerometerSensor">AccelerometerSensor</a>, <a title="redvox.api900.sensors.gyroscope_sensor.GyroscopeSensor" href="../api900/sensors/gyroscope_sensor.html#redvox.api900.sensors.gyroscope_sensor.GyroscopeSensor">GyroscopeSensor</a>, <a title="redvox.api900.sensors.magnetometer_sensor.MagnetometerSensor" href="../api900/sensors/magnetometer_sensor.html#redvox.api900.sensors.magnetometer_sensor.MagnetometerSensor">MagnetometerSensor</a>, <a title="redvox.api900.sensors.light_sensor.LightSensor" href="../api900/sensors/light_sensor.html#redvox.api900.sensors.light_sensor.LightSensor">LightSensor</a>, <a title="redvox.api900.sensors.infrared_sensor.InfraredSensor" href="../api900/sensors/infrared_sensor.html#redvox.api900.sensors.infrared_sensor.InfraredSensor">InfraredSensor</a>, <a title="redvox.api900.sensors.image_sensor.ImageSensor" href="../api900/sensors/image_sensor.html#redvox.api900.sensors.image_sensor.ImageSensor">ImageSensor</a>], packet_length_s: float, column_id: str) ‑> <a title="redvox.common.sensor_data.SensorData" href="sensor_data.html#redvox.common.sensor_data.SensorData">SensorData</a></span>
</code></dt>
<dd>
<div class="desc"><p>read a sensor that does not have mic data from an api900 data packet
:param sensor: the non-mic api900 sensor to read
:param packet_length_s: float, the length of the data packet in seconds
:param column_id: string, used to name the columns
:return: generic SensorData object</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def read_api900_non_mic_sensor(sensor: api900_io.RedvoxSensor, packet_length_s: float, column_id: str) -&gt; SensorData:
    &#34;&#34;&#34;
    read a sensor that does not have mic data from an api900 data packet
    :param sensor: the non-mic api900 sensor to read
    :param packet_length_s: float, the length of the data packet in seconds
    :param column_id: string, used to name the columns
    :return: generic SensorData object
    &#34;&#34;&#34;
    timestamps = sensor.timestamps_microseconds_utc()
    if type(sensor) in [api900_io.AccelerometerSensor, api900_io.MagnetometerSensor, api900_io.GyroscopeSensor]:
        data_for_df = np.transpose([sensor.payload_values_x(), sensor.payload_values_y(), sensor.payload_values_z()])
        columns = [f&#34;{column_id}_x&#34;, f&#34;{column_id}_y&#34;, f&#34;{column_id}_z&#34;]
    else:
        data_for_df = np.transpose(sensor.payload_values())
        columns = [column_id]
    return SensorData(sensor.sensor_name(), pd.DataFrame(data_for_df, index=timestamps, columns=columns),
                      len(timestamps) / packet_length_s, False)</code></pre>
</details>
</dd>
<dt id="redvox.common.load_sensor_data.read_api900_wrapped_packet"><code class="name flex">
<span>def <span class="ident">read_api900_wrapped_packet</span></span>(<span>wrapped_packet: <a title="redvox.api900.wrapped_redvox_packet.WrappedRedvoxPacket" href="../api900/wrapped_redvox_packet.html#redvox.api900.wrapped_redvox_packet.WrappedRedvoxPacket">WrappedRedvoxPacket</a>) ‑> typing.Dict[<a title="redvox.common.sensor_data.SensorType" href="sensor_data.html#redvox.common.sensor_data.SensorType">SensorType</a>, <a title="redvox.common.sensor_data.SensorData" href="sensor_data.html#redvox.common.sensor_data.SensorData">SensorData</a>]</span>
</code></dt>
<dd>
<div class="desc"><p>reads the data from a wrapped api900 redvox packet into a dictionary of generic data
:param wrapped_packet: a wrapped api900 redvox packet
:return: a dictionary containing all the sensor data</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def read_api900_wrapped_packet(wrapped_packet: api900_io.WrappedRedvoxPacket) -&gt; Dict[SensorType, SensorData]:
    &#34;&#34;&#34;
    reads the data from a wrapped api900 redvox packet into a dictionary of generic data
    :param wrapped_packet: a wrapped api900 redvox packet
    :return: a dictionary containing all the sensor data
    &#34;&#34;&#34;
    packet_length_s: float = wrapped_packet.duration_s()
    data_dict: Dict[SensorType, SensorData] = {}
    # there are 9 api900 sensors
    if wrapped_packet.has_microphone_sensor():
        sample_rate_hz = wrapped_packet.microphone_sensor().sample_rate_hz()
        data_for_df = wrapped_packet.microphone_sensor().payload_values()
        timestamps = calc_evenly_sampled_timestamps(
            wrapped_packet.microphone_sensor().first_sample_timestamp_epoch_microseconds_utc(),
            fs.get_num_points_from_sample_rate(sample_rate_hz), sample_rate_hz)
        data_dict[SensorType.AUDIO] = SensorData(wrapped_packet.microphone_sensor().sensor_name(),
                                                 pd.DataFrame(data_for_df, index=timestamps, columns=[&#34;microphone&#34;]),
                                                 sample_rate_hz, True)
    if wrapped_packet.has_accelerometer_sensor():
        data_dict[SensorType.ACCELEROMETER] = read_api900_non_mic_sensor(wrapped_packet.accelerometer_sensor(),
                                                                         packet_length_s, &#34;accelerometer&#34;)
    if wrapped_packet.has_magnetometer_sensor():
        data_dict[SensorType.MAGNETOMETER] = read_api900_non_mic_sensor(wrapped_packet.magnetometer_sensor(),
                                                                        packet_length_s, &#34;magnetometer&#34;)
    if wrapped_packet.has_gyroscope_sensor():
        data_dict[SensorType.GYROSCOPE] = read_api900_non_mic_sensor(wrapped_packet.gyroscope_sensor(),
                                                                     packet_length_s, &#34;gyroscope&#34;)
    if wrapped_packet.has_barometer_sensor():
        data_dict[SensorType.PRESSURE] = read_api900_non_mic_sensor(wrapped_packet.barometer_sensor(),
                                                                    packet_length_s, &#34;barometer&#34;)
    if wrapped_packet.has_light_sensor():
        data_dict[SensorType.LIGHT] = read_api900_non_mic_sensor(wrapped_packet.light_sensor(),
                                                                 packet_length_s, &#34;light&#34;)
    if wrapped_packet.has_infrared_sensor():
        data_dict[SensorType.INFRARED] = read_api900_non_mic_sensor(wrapped_packet.infrared_sensor(),
                                                                    packet_length_s, &#34;infrared&#34;)
    if wrapped_packet.has_image_sensor():
        data_dict[SensorType.IMAGE] = read_api900_non_mic_sensor(wrapped_packet.image_sensor(),
                                                                 packet_length_s, &#34;image&#34;)
    if wrapped_packet.has_location_sensor():
        timestamps = wrapped_packet.location_sensor().timestamps_microseconds_utc()
        data_for_df = np.transpose([wrapped_packet.location_sensor().payload_values_latitude(),
                                    wrapped_packet.location_sensor().payload_values_longitude(),
                                    wrapped_packet.location_sensor().payload_values_altitude(),
                                    wrapped_packet.location_sensor().payload_values_speed(),
                                    wrapped_packet.location_sensor().payload_values_accuracy()])
        columns = [&#34;latitude&#34;, &#34;longitude&#34;, &#34;altitude&#34;, &#34;speed&#34;, &#34;accuracy&#34;]
        data_dict[SensorType.LOCATION] = SensorData(wrapped_packet.location_sensor().sensor_name(),
                                                    pd.DataFrame(data_for_df, index=timestamps, columns=columns),
                                                    len(timestamps) / packet_length_s, False)
    return data_dict</code></pre>
</details>
</dd>
<dt id="redvox.common.load_sensor_data.read_apim_single_sensor"><code class="name flex">
<span>def <span class="ident">read_apim_single_sensor</span></span>(<span>sensor: <a title="redvox.api1000.wrapped_redvox_packet.sensors.single.Single" href="../api1000/wrapped_redvox_packet/sensors/single.html#redvox.api1000.wrapped_redvox_packet.sensors.single.Single">Single</a>, packet_length_s: float, column_id: str) ‑> <a title="redvox.common.sensor_data.SensorData" href="sensor_data.html#redvox.common.sensor_data.SensorData">SensorData</a></span>
</code></dt>
<dd>
<div class="desc"><p>read a sensor that has a single data channel from an api M data packet
:param sensor: the single channel api M sensor to read
:param packet_length_s: float, the length of the data packet in seconds
:param column_id: string, used to name the columns
:return: generic SensorData object</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def read_apim_single_sensor(sensor: single.Single, packet_length_s: float, column_id: str) -&gt; SensorData:
    &#34;&#34;&#34;
    read a sensor that has a single data channel from an api M data packet
    :param sensor: the single channel api M sensor to read
    :param packet_length_s: float, the length of the data packet in seconds
    :param column_id: string, used to name the columns
    :return: generic SensorData object
    &#34;&#34;&#34;
    timestamps = sensor.get_timestamps().get_timestamps()
    data_for_df = np.transpose([sensor.get_samples().get_values()])
    columns = [column_id]
    return SensorData(sensor.get_sensor_description(), pd.DataFrame(data_for_df, index=timestamps, columns=columns),
                      len(timestamps) / packet_length_s, False)</code></pre>
</details>
</dd>
<dt id="redvox.common.load_sensor_data.read_apim_xyz_sensor"><code class="name flex">
<span>def <span class="ident">read_apim_xyz_sensor</span></span>(<span>sensor: <a title="redvox.api1000.wrapped_redvox_packet.sensors.xyz.Xyz" href="../api1000/wrapped_redvox_packet/sensors/xyz.html#redvox.api1000.wrapped_redvox_packet.sensors.xyz.Xyz">Xyz</a>, packet_length_s: float, column_id: str) ‑> <a title="redvox.common.sensor_data.SensorData" href="sensor_data.html#redvox.common.sensor_data.SensorData">SensorData</a></span>
</code></dt>
<dd>
<div class="desc"><p>read a sensor that has xyz data channels from an api M data packet
:param sensor: the xyz api M sensor to read
:param packet_length_s: float, the length of the data packet in seconds
:param column_id: string, used to name the columns
:return: generic SensorData object</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def read_apim_xyz_sensor(sensor: xyz.Xyz, packet_length_s: float, column_id: str) -&gt; SensorData:
    &#34;&#34;&#34;
    read a sensor that has xyz data channels from an api M data packet
    :param sensor: the xyz api M sensor to read
    :param packet_length_s: float, the length of the data packet in seconds
    :param column_id: string, used to name the columns
    :return: generic SensorData object
    &#34;&#34;&#34;
    timestamps = sensor.get_timestamps().get_timestamps()
    data_for_df = np.transpose([sensor.get_x_samples().get_values(),
                                sensor.get_y_samples().get_values(),
                                sensor.get_z_samples().get_values()])
    columns = [f&#34;{column_id}_x&#34;, f&#34;{column_id}_y&#34;, f&#34;{column_id}_z&#34;]
    return SensorData(sensor.get_sensor_description(), pd.DataFrame(data_for_df, index=timestamps, columns=columns),
                      len(timestamps) / packet_length_s, False)</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="redvox.common" href="index.html">redvox.common</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="redvox.common.load_sensor_data.calc_evenly_sampled_timestamps" href="#redvox.common.load_sensor_data.calc_evenly_sampled_timestamps">calc_evenly_sampled_timestamps</a></code></li>
<li><code><a title="redvox.common.load_sensor_data.load_apim_wrapped_packet" href="#redvox.common.load_sensor_data.load_apim_wrapped_packet">load_apim_wrapped_packet</a></code></li>
<li><code><a title="redvox.common.load_sensor_data.load_file_range_from_api900" href="#redvox.common.load_sensor_data.load_file_range_from_api900">load_file_range_from_api900</a></code></li>
<li><code><a title="redvox.common.load_sensor_data.load_from_file_range_api_m" href="#redvox.common.load_sensor_data.load_from_file_range_api_m">load_from_file_range_api_m</a></code></li>
<li><code><a title="redvox.common.load_sensor_data.load_from_mseed" href="#redvox.common.load_sensor_data.load_from_mseed">load_from_mseed</a></code></li>
<li><code><a title="redvox.common.load_sensor_data.load_station_from_api900" href="#redvox.common.load_sensor_data.load_station_from_api900">load_station_from_api900</a></code></li>
<li><code><a title="redvox.common.load_sensor_data.load_station_from_apim" href="#redvox.common.load_sensor_data.load_station_from_apim">load_station_from_apim</a></code></li>
<li><code><a title="redvox.common.load_sensor_data.read_all_in_dir" href="#redvox.common.load_sensor_data.read_all_in_dir">read_all_in_dir</a></code></li>
<li><code><a title="redvox.common.load_sensor_data.read_api900_in_dir_exact" href="#redvox.common.load_sensor_data.read_api900_in_dir_exact">read_api900_in_dir_exact</a></code></li>
<li><code><a title="redvox.common.load_sensor_data.read_api900_non_mic_sensor" href="#redvox.common.load_sensor_data.read_api900_non_mic_sensor">read_api900_non_mic_sensor</a></code></li>
<li><code><a title="redvox.common.load_sensor_data.read_api900_wrapped_packet" href="#redvox.common.load_sensor_data.read_api900_wrapped_packet">read_api900_wrapped_packet</a></code></li>
<li><code><a title="redvox.common.load_sensor_data.read_apim_single_sensor" href="#redvox.common.load_sensor_data.read_apim_single_sensor">read_apim_single_sensor</a></code></li>
<li><code><a title="redvox.common.load_sensor_data.read_apim_xyz_sensor" href="#redvox.common.load_sensor_data.read_apim_xyz_sensor">read_apim_xyz_sensor</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.1</a>.</p>
</footer>
</body>
</html>